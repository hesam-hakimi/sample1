Add an “Explain Errors with LLM” capability.

Goal:
Whenever ANY step fails (db connect, SQL execution, missing meta tables, LLM JSON parsing, validation errors, unexpected exceptions),
the app should:
1) Capture the error + context (user question, stage, SQL if any, db status).
2) Call the LLM to convert it into a user-friendly message.
3) Show that friendly message in the chat.
4) Never leak secrets (tokens, connection string, full stack traces, full server names if sensitive).

Constraints:
- Do NOT use Runner/Agent.
- Use existing AzureOpenAI MSI client in app/llm_client.py.
- Must work even if meta.* missing.
- Must not create infinite loops: if the LLM call fails, fallback to a simple canned message.

========================================================
1) Create a dedicated error explainer module
========================================================
Create: app/error_explainer.py

Implement:
- class ErrorExplainer:
   def __init__(self, llm: LLMClient): ...
   def explain(
        self,
        user_text: str,
        stage: str,
        err: Exception,
        *,
        sql: str = "",
        meta_ready: bool | None = None,
        db_server_hint: str = "",
        extra: dict | None = None,
   ) -> str

Behavior:
- Build a SAFE error payload:
  - error_type: type(err).__name__
  - error_message: str(err) truncated to 1500 chars
  - stage: e.g. "metadata_check", "sql_validation", "db_execute", "llm_plan", "llm_final", "formatting", "ui_handler"
  - sql: include ONLY if already generated by our system; truncate to 2000 chars
  - user_text: original question truncated
  - meta_ready: bool if known
  - IMPORTANT: sanitize sensitive values:
    - remove any "Bearer " tokens
    - remove connection strings
    - remove anything that looks like a secret (AZURE_OPENAI_KEY, password, etc)
- Create a system prompt for the explainer with strict rules:
  - Write in plain language suitable for non-technical users.
  - Provide: what happened, why it might happen, what the user can do next.
  - Include next-step actions (e.g., “try List Tables”, “confirm DB name”, “contact admin for permissions”).
  - Never mention internal stack traces.
  - If it's a permission issue, clearly say “You don’t have permission to create tables in this database”.
  - If meta tables missing, say “Metadata isn’t installed in this DB; the system can list tables but can’t auto-generate correct joins yet.”
- Call llm.chat_messages(...) with a short message list:
  - system: explainer rules
  - user: JSON payload (as text)
- Return the LLM response text.
- If LLM call throws, return fallback:
  "Sorry—something went wrong. Please try again. Details: <short sanitized message>"

Add tests:
- tests/test_error_explainer.py:
  - mock LLMClient to return a friendly message
  - ensure secrets are redacted
  - ensure fallback works when LLM throws

========================================================
2) Add consistent exception handling in the pipeline
========================================================
Update: app/nl2sql.py

In handle_user_turn(...):
Wrap EACH stage with try/except and call ErrorExplainer.explain(...)

Stages to label:
- "greeting"
- "metadata_check"
- "list_tables"
- "llm_plan"
- "metadata_query_execute"
- "llm_final"
- "sql_validation"
- "confirmation"
- "db_execute"
- "result_formatting"

On exception:
- Use ErrorExplainer to produce user_friendly
- Append assistant message with user_friendly
- DO NOT crash, keep UI responsive
- Clear pending_sql if the error happened during execution (so user doesn't get stuck)

Ensure we pass relevant context:
- user_text
- stage
- sql if known (pending sql or executed sql)
- meta_ready from db.metadata_ready()
- For DB errors, include a non-sensitive db hint:
  e.g., db_server_hint = last 2-3 segments only or just "(configured)" to avoid leaking full host

========================================================
3) Improve db error mapping FIRST, then LLM refine
========================================================
Update: app/db.py

Add:
- def classify_db_error(err: Exception) -> dict:
   returns:
     category: one of ["timeout","auth","permission","object_missing","syntax","unknown"]
     hint: short action-oriented message
     code: SQLSTATE if present (HYT00, 42000, 42S02, etc)

Examples:
- HYT00 -> timeout/network
- 42000 + "permission denied" -> permission
- 42S02 invalid object name -> object_missing

Then in nl2sql error handler:
- pass extra={"db_category":..., "db_hint":..., "db_code":...} to ErrorExplainer
So the LLM gets structured signal and produces consistent guidance.

Add tests:
- tests/test_db_classify.py with mocked pyodbc.Error args for HYT00, 42000, 42S02.

========================================================
4) UI changes
========================================================
Update: app/ui.py
- Ensure all handlers call nl2sql.handle_user_turn and never raise uncaught exceptions.
- If an exception escapes, catch in UI handler and show ErrorExplainer-based message (stage="ui_handler").

========================================================
Acceptance criteria
========================================================
- For any error (meta missing, create table permission, db timeout, invalid object, LLM JSON parsing),
  the user sees a clear message like:
  “I can’t generate SQL yet because metadata isn’t installed in this database. You can click List Tables or specify a table name…”
  or
  “I can connect, but I don’t have permission to create tables in this database. Ask an admin…”
- No stack traces shown in chat.
- Secrets are redacted.
- If LLM itself is down, the fallback message still appears.
- pytest -q passes.

Deliverable:
Provide full updated contents for:
- app/error_explainer.py (new)
- app/nl2sql.py (updated)
- app/db.py (updated)
- app/ui.py (updated if needed)
- tests/test_error_explainer.py (new)
- tests/test_db_classify.py (new)
